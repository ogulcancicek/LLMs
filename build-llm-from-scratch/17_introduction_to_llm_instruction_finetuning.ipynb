{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d7U1cQNCBUn"
      },
      "source": [
        "## Introduction to LLM Intruction Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3mWY7o2lCBUo"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as f\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPecE9fKCBUp"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NNqv7nDICBUp"
      },
      "outputs": [],
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cso7JG6ZCBUp"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EkJ5HG7CCBUp"
      },
      "outputs": [],
      "source": [
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7RnG8mFQCBUq"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
        "    idx = idx.to(model.tok_emb.weight.device)\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Filter logits with top_k sampling\n",
        "        if top_k is not None:\n",
        "            top_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_logits[:, -1]\n",
        "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        if temperature > 0.0:\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # apply softmax to get probabilities\n",
        "            probas = torch.softmax(logits, dim=-1)\n",
        "\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probas, num_samples=1)\n",
        "\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "\n",
        "        if idx_next == eos_id:\n",
        "            break\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fpbZ2SJECBUq"
      },
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    idx = idx.to(model.tok_emb.weight.device)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size,\n",
        "        # E.g., if LLm support only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 token are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond) # (B, seq_len, vocab_size)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocabz_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1) # (batch, n_tokens+1)\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1sdgydOnCBUq"
      },
      "outputs": [],
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size= model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model,\n",
        "            idx=encoded,\n",
        "            max_new_tokens=50,\n",
        "            context_size=context_size\n",
        "        )\n",
        "\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace('\\n', ' ')) # Compact print format\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA5SOezWCBUq"
      },
      "source": [
        "### GPT-2 Model From Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DRxtyjgYCBUq"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
        "            GELU(), ## Activation\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5CoFBw0CCBUq"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HMV_VyfqCBUq"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        # 2*4*768\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "        # 2*4*768"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qFNV8PyyCBUr"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCnZ63VVCBUr"
      },
      "source": [
        "### Preprating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8luYM3LbCBUr",
        "outputId": "903751db-8dd1-4ac6-fc0f-d5d404693f42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "import ssl\n",
        "\n",
        "def dowload_and_load_file(file_path, url):\n",
        "    ssl_context = ssl.create_default_context()\n",
        "    ssl_context.check_hostname = False\n",
        "    ssl_context.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "            text_data = response.read().decode('utf-8')\n",
        "        with open(file_path, 'w', encoding='utf-8')  as file:\n",
        "            file.write(text_data)\n",
        "    else:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text_data = file.read()\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "file_path = 'instruction-data.json'\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = dowload_and_load_file(file_path, url)\n",
        "print('Number of entries:', len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32p-D1QXCBUr",
        "outputId": "83d4f368-ff4e-4ef0-c0af-3385d1e0c973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ],
      "source": [
        "print('Example entry:\\n', data[50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANOVakiACBUr",
        "outputId": "c5bede44-474e-4c11-e6a6-594099957239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Another example entry:\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ],
      "source": [
        "print('Another example entry:\\n', data[999])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHvUJambCBUr"
      },
      "source": [
        "#### Converting Instructions Into Alpaca Format\n",
        "\n",
        "Some common intruction formats:\n",
        "- Alpaca prompt style\n",
        "- Phi 3 Microsoft prompt style"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "G7PYOW_TCBUr"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry['input'] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwkIFr5xCBUr",
        "outputId": "3fac467f-d44b-4053-8cf6-0b9c8223270a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX-WKfBFCBUr",
        "outputId": "59033b7e-f670-4f5e-9c31-a2ce7636e375"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgv8Yx34CBUs"
      },
      "source": [
        "#### Splitting Data Into Train-Test-Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wKr0tMuNCBUs"
      },
      "outputs": [],
      "source": [
        "train_portion = int(len(data) * 0.85) # 85% for training\n",
        "test_portion = int(len(data) * 0.1)   # 10% for test\n",
        "val_portion = len(data) - train_portion - test_portion # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion+test_portion]\n",
        "val_data = data[train_portion+test_portion:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "par9CQ9-CBUs",
        "outputId": "6d8f4192-f8dc-42aa-da6f-a1ab851ac8a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(935, 110, 55)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_data), len(test_data), len(val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1Y0BKFuCBUs"
      },
      "source": [
        "### Organizing Data Into Training Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pE1JJLjsCBUs"
      },
      "outputs": [],
      "source": [
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            intruction_plus_input = format_input(entry)\n",
        "            response_text = f\"### Response:\\n{entry['output']}\"\n",
        "            full_text = intruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yOIT8R3CBUs"
      },
      "source": [
        "Now, we'll implement custom collate function:\n",
        "- Step 1: Find the longest sequence in the batch\n",
        "- Step 2: Pad and prepare inputs\n",
        "- Step 3: Remove extra padded token added earlier\n",
        "- Step 4: Convert list of inputs to tensor and transfer to target device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NReIeSrgCBUs"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_1(batch, pad_token_id=50256, device='cpu'):\n",
        "    # Find the longest sequence in the batch\n",
        "    # and increase the max length by +1, which will add one extra\n",
        "    # padding token below\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    inputs_lst = []\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        new_item += [pad_token_id]\n",
        "\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
        "        )\n",
        "\n",
        "        # Via padded[:-1], we remove the extra padded token\n",
        "        # that has been added via the +1 setting in batch_max_length\n",
        "        # (the extra padding token will be relevant in later codes)\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dImlUMbCBUs",
        "outputId": "8b01e0a4-fa55-43b2-b56e-3516bd02abc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_draft_1(batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAp4pBW4CBUs"
      },
      "source": [
        "#### Creating Target Token IDs for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3ttxOvcXCBUs"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_2(batch, pad_token_id=50256, device='cpu'):\n",
        "    # Find the longest sequence in the batch\n",
        "    # and increase the max length by +1, which will add one extra\n",
        "    # padding token below\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    inputs_lst, targets_lst = [], []\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        new_item += [pad_token_id]\n",
        "\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
        "        )\n",
        "\n",
        "        inputs = torch.tensor(padded[:-1]) # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:]) # Shift +1 to the right for targets\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQsP_U1tCBUs",
        "outputId": "753e2f89-159f-4863-bb48-67fb7efde614"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs:\n",
            " tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "\n",
            "Targets:\n",
            " tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "input_tensor, target_tensor = custom_collate_draft_2(batch)\n",
        "\n",
        "print('Inputs:\\n', input_tensor)\n",
        "print('\\nTargets:\\n', target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjqtUprYCBUt"
      },
      "source": [
        "In the next step, we assign a -100 placeholder value to all padding tokens.\n",
        "\n",
        "This special value allows us to exclude these padding tokens from contrubting to the training loss calculation.\n",
        "\n",
        "**Note:** We retain one end-of-text token, ID 50256, in the target list. This allows the LLM to learn when to generate an end-of-text token in response to instruction, which we use as an indicator that the generated response is completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "x4AmpXgFCBUt"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device='cpu'\n",
        "):\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        new_item += [pad_token_id]\n",
        "\n",
        "        padded = (new_item + [pad_token_id] * (batch_max_length - len(new_item)))\n",
        "\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        targets = torch.tensor(padded[1:])\n",
        "\n",
        "        # Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6pmj6LLCBUt",
        "outputId": "e7b9c2a8-bf1f-40e5-9c90-074df79accb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inputs:\n",
            " tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "\n",
            "Targets:\n",
            " tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "input_tensor, target_tensor = custom_collate_fn(batch)\n",
        "\n",
        "print('Inputs:\\n', input_tensor)\n",
        "print('\\nTargets:\\n', target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdnfvNrOCBUt"
      },
      "source": [
        "#### Understanding the logic behind modified collate function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tB4oYu6ZCBUt",
        "outputId": "6f42d6cb-966e-4e9b-9364-78e4e8c44acb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1269)\n"
          ]
        }
      ],
      "source": [
        "logits_1 = torch.tensor(\n",
        "    [[-1.0, 1.0], # 1st training example\n",
        "     [-0.5, 1.5]] # 2nd training exmaple\n",
        ")\n",
        "\n",
        "targets_1 = torch.tensor([0, 1])\n",
        "\n",
        "loss_1 = f.cross_entropy(logits_1, targets_1)\n",
        "print(loss_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pbEkFF-CBUt",
        "outputId": "ad366031-13b5-4dba-af7e-3bc23b8a8d77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.7936)\n"
          ]
        }
      ],
      "source": [
        "## Adding an additional token ID will, as we would expect, affect the loss function\n",
        "logits_2 = torch.tensor(\n",
        "    [[-1.0, 1.0],\n",
        "     [-0.5, 1.5],\n",
        "     [-0.5, 1.5]] # New 3rd training example\n",
        "\n",
        ")\n",
        "\n",
        "targets_2 = torch.tensor([0, 1, 1])\n",
        "\n",
        "loss_2 = f.cross_entropy(logits_2, targets_2)\n",
        "print(loss_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCaVg8MnCBUy",
        "outputId": "e3864e1c-2a1d-4753-9c52-e8c5fd2c834f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.1269)\n"
          ]
        }
      ],
      "source": [
        "## If we replace the third target token ID with -100 (default ignore_index paramteter)\n",
        "targets_3 = torch.tensor([0, 1, -100])\n",
        "\n",
        "loss_3 = f.cross_entropy(logits_2, targets_3)\n",
        "print(loss_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfuGfDZtCBUy"
      },
      "source": [
        "#### Masking Target Token IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJBjvcTmCBUy"
      },
      "source": [
        "It is also common to mask out the target token IDs that correspond to the instruction.\n",
        "\n",
        "By masking out the target token IDs that correspond to the instruction, the LLM cross entropy loss is only computed for the generated response target IDs.\n",
        "\n",
        "By masking out the target tokens, the model is trained to focus on generating accurate responses rather than additionally also memorizing instructions, which can help with reducing overfitting.\n",
        "\n",
        "Currently, researches are divided on whether masing the instructions is universally benefical during instruction finetuning.\n",
        "\n",
        "For instance, a recent paper titled \"Instruction Tuning With Loss Over Instructions\" demonstrated that not masking the instructions benefits the LLM performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51YHpNUDCBUy"
      },
      "source": [
        "### Creating DataLoaders From An Instruction Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hado2o_vCBUz"
      },
      "source": [
        "The custom_collate_fn includes code to move the input and target tensors (for\n",
        "example, torch.stack(inputs_lst).to(device)) to a specified device, which can be\n",
        "either \"cpu\" or \"cuda\" (for GPUs), or optionally \"mps\" for Macs with Apple Silicon chips.\n",
        "\n",
        "In previous chapters, we moved the data onto the target device (for example, the GPU\n",
        "memory when device=\"cuda\") in the main training loop. Having this as part of the collate\n",
        "function offers the advantage of performing this device transfer process as a background\n",
        "process outside the training loop, preventing it from blocking the GPU during model\n",
        "training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "XayftGG8CBUz"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding('gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoAaMZNcCBUz",
        "outputId": "87b97737-975b-4c5f-897e-26b9d5a639f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device: mps\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = 'mps'\n",
        "else:\n",
        "    device = 'cpu'\n",
        "\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print('device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "BnSjpoFSCBUz"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "LuE-HJgSCBUz"
      },
      "outputs": [],
      "source": [
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex0iXsPbCBUz",
        "outputId": "405b5e26-fb0a-4492-a521-5e0b3638ebaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loader:\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 86]) torch.Size([8, 86])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 56]) torch.Size([8, 56])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 85]) torch.Size([8, 85])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 55]) torch.Size([8, 55])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dzhv3UK8CBUz"
      },
      "source": [
        "### Loading Pre-trained LLM Weights (GPT-2 355M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRgqlqOGCBUz",
        "outputId": "d9b5276a-dd7a-4ace-dc06-6a7fbf6a7e32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/opt/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/checkpoint\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/encoder.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/hparams.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.data-00000-of-00001\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.index\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/model.ckpt.meta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "from gpt_download3 import download_and_load_gpt2\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scuSGNDvCBUz"
      },
      "source": [
        "#### Test Pre-Trained Model on Instruction Based Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cekhZY58CBUz"
      },
      "source": [
        "Before diving into finetuning the model, let's take a moment to assess the pretrained LLM's performance on on of the validation tasks by comparing its output to the expected response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aUyxjaBCBUz",
        "outputId": "f25e9260-3177-44ce-ec26-f4c8bada6daf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "x22u8dDDCBUz"
      },
      "outputs": [],
      "source": [
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG['context_length'],\n",
        "    eos_id=50256\n",
        ")\n",
        "\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaAlWHlRCBUz",
        "outputId": "cbd2dae8-1eb3-4182-8aac-68274d587e99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Response:\n",
            "\n",
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "response_text = generated_text[len(input_text):].strip()\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUMw_vojCBUz"
      },
      "source": [
        "As we can see from the output, the pretrained model is not yet capable of correctly following the given instruction.\n",
        "\n",
        "While it does create a \"Response\" section, it simply repeats the original input sentence and part of the instruction, failiting to convert the active sentence to passive voice as requested."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq4padOmCBU0"
      },
      "source": [
        "### Finetuning the LLM on Instruction Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WM6-v5lBCBU0"
      },
      "source": [
        "#### Training Utils\n",
        "\n",
        "Step 1: Set model to training mode\n",
        "\n",
        "Step 2: Reset loss gradients from previous batch iteration\n",
        "\n",
        "Step 3: Calculate loss gradients\n",
        "\n",
        "Step 4: Update model weights using loss gradients\n",
        "\n",
        "Step 5: New: track examples instead of tokens\n",
        "\n",
        "Step 6: Optional evaluation step\n",
        "\n",
        "Step 7: Optionally calculate accuracy after each epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "fGwbLAP-CBU0"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch) # (B, Seq_len, vocab_size)\n",
        "    loss = f.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float('nan')\n",
        "    elif num_batches == None:\n",
        "        num_batches == len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "UST_cYbzCBU0"
      },
      "outputs": [],
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tokens_seen += input_batch.numel() # Return total number of elements\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader,\n",
        "                                                      device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyOunyAmCBU0"
      },
      "source": [
        "#### Finetune the Pre-Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UEPc77qCBU0",
        "outputId": "515b641c-863c-4d30-9a13-d811c050db4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Loss: 4.168272972106934\n",
            "Validation Loss 4.1019439697265625\n"
          ]
        }
      ],
      "source": [
        "## INITIAL LOSS OF MODEL ON TRAIN AND VALIDATION DATALOADERS\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print('Training Loss:', train_loss.item())\n",
        "print('Validation Loss', val_loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kbeti-OVCBU0",
        "outputId": "eaa8b046-2cf6-4e41-f2e4-cac0372f79a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "## Start Context\n",
        "\n",
        "print(format_input(val_data[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVkvTmkACBU0",
        "outputId": "624b6501-60b7-4de2-eec6-3e91bc400b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.735, Val loss 2.730\n",
            "Ep 1 (Step 000010): Train loss 1.053, Val loss 0.985\n",
            "Ep 1 (Step 000020): Train loss 0.784, Val loss 0.923\n",
            "Ep 1 (Step 000030): Train loss 0.771, Val loss 0.861\n",
            "Ep 1 (Step 000040): Train loss 0.689, Val loss 0.838\n",
            "Ep 1 (Step 000050): Train loss 0.661, Val loss 0.817\n",
            "Ep 1 (Step 000060): Train loss 0.691, Val loss 0.775\n",
            "Ep 1 (Step 000070): Train loss 0.633, Val loss 0.755\n",
            "Ep 1 (Step 000080): Train loss 0.601, Val loss 0.745\n",
            "Ep 1 (Step 000090): Train loss 0.539, Val loss 0.727\n",
            "Ep 1 (Step 000100): Train loss 0.579, Val loss 0.709\n",
            "Ep 1 (Step 000110): Train loss 0.623, Val loss 0.696\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The\n",
            "Ep 2 (Step 000120): Train loss 0.454, Val loss 0.691\n",
            "Ep 2 (Step 000130): Train loss 0.434, Val loss 0.704\n",
            "Ep 2 (Step 000140): Train loss 0.397, Val loss 0.702\n",
            "Ep 2 (Step 000150): Train loss 0.447, Val loss 0.697\n",
            "Ep 2 (Step 000160): Train loss 0.414, Val loss 0.691\n",
            "Ep 2 (Step 000170): Train loss 0.408, Val loss 0.698\n",
            "Ep 2 (Step 000180): Train loss 0.416, Val loss 0.691\n",
            "Ep 2 (Step 000190): Train loss 0.382, Val loss 0.684\n",
            "Ep 2 (Step 000200): Train loss 0.430, Val loss 0.698\n",
            "Ep 2 (Step 000210): Train loss 0.329, Val loss 0.684\n",
            "Ep 2 (Step 000220): Train loss 0.337, Val loss 0.691\n",
            "Ep 2 (Step 000230): Train loss 0.285, Val loss 0.675\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United States?### Response:\n",
            "Ep 3 (Step 000240): Train loss 0.320, Val loss 0.702\n",
            "Ep 3 (Step 000250): Train loss 0.253, Val loss 0.721\n",
            "Ep 3 (Step 000260): Train loss 0.298, Val loss 0.706\n",
            "Ep 3 (Step 000270): Train loss 0.309, Val loss 0.709\n",
            "Ep 3 (Step 000280): Train loss 0.316, Val loss 0.746\n",
            "Ep 3 (Step 000290): Train loss 0.258, Val loss 0.710\n",
            "Ep 3 (Step 000300): Train loss 0.281, Val loss 0.710\n",
            "Ep 3 (Step 000310): Train loss 0.260, Val loss 0.721\n",
            "Ep 3 (Step 000320): Train loss 0.252, Val loss 0.696\n",
            "Ep 3 (Step 000330): Train loss 0.265, Val loss 0.698\n",
            "Ep 3 (Step 000340): Train loss 0.237, Val loss 0.686\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The\n",
            "Training completed in 1.11 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(params=model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 3\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(model,\n",
        "                                                          train_loader,\n",
        "                                                          val_loader,\n",
        "                                                          optimizer=optimizer,\n",
        "                                                          device=device,\n",
        "                                                          num_epochs=num_epochs,\n",
        "                                                          eval_freq=10,\n",
        "                                                          eval_iter=5,\n",
        "                                                          start_context=format_input(val_data[0]),\n",
        "                                                          tokenizer=tokenizer)\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP5RELL6F15x"
      },
      "source": [
        "#### Plotting Training and Validation Loss Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "QNolx5xXDtiF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Convert train_losses and val_losses to lists of Python scalars\n",
        "    train_losses = [loss.cpu().item() for loss in train_losses]\n",
        "    val_losses = [loss.cpu().item() for loss in val_losses]\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "zWnp_WCcF7v3",
        "outputId": "137b667a-3855-4af8-b3d0-553c1aec4e8c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apcuKaHCHvcK"
      },
      "source": [
        "As we cann se in the loss plot shown above, the model's performance on both the training and validation sets improves substantially over the course of training.\n",
        "\n",
        "The rapid decrease in losses during the initial phase indicates that the model is quickly learning meaningful patterns and representations from the data. Then, as training progresses to the second epoch, the losses continue to decrease but at slower rate, suggesting that the model is finetuning its learning representations and converging to a stable solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz0QIQAuIUqe"
      },
      "source": [
        "### Extracting and Saving Responses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQShnkY4G6Xl"
      },
      "source": [
        "After finetuning the LLM on the training portion of the instruction dataset as described in the previous section, we now proceed to evaluation its performance on the held-out test set.\n",
        "\n",
        "To accomplish this, we first extract the model-generated responses for each input in the test dataset and collect them for manual analsis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYvFv552F9DN",
        "outputId": "71d66c09-7f54-4c88-e2d0-4296d8b86237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud typically associated with thunderstorms is a cumulus cloud.\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is the periodic symbol for chlorine?\n",
            "\n",
            "Correct response:\n",
            ">> The periodic symbol for chlorine is Cl.\n",
            "\n",
            "Model response:\n",
            ">> The periodic symbol for chlorine is C.\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Correct the punctuation in the sentence.\n",
            "\n",
            "### Input:\n",
            "Its time to go home.\n",
            "\n",
            "Correct response:\n",
            ">> The corrected sentence should be: 'It's time to go home.'\n",
            "\n",
            "Model response:\n",
            ">> The corrected sentence should be: 'Its time to go home.'\n",
            "\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "for entry in test_data[:5]:\n",
        "  input_text = format_input(entry)\n",
        "\n",
        "  token_ids = generate(\n",
        "      model,\n",
        "      idx=text_to_token_ids(input_text, tokenizer),\n",
        "      max_new_tokens=256,\n",
        "      context_size=BASE_CONFIG['context_length'],\n",
        "      eos_id=50256\n",
        "  )\n",
        "\n",
        "  generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "  response_text = (\n",
        "      generated_text[len(input_text):]\n",
        "      .replace('### Response:', \"\")\n",
        "      .strip()\n",
        "  )\n",
        "\n",
        "  print(input_text)\n",
        "  print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "  print(f\"\\nModel response:\\n>> {response_text.strip()}\\n\")\n",
        "  print('---'*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWq7G3hYTVYF"
      },
      "source": [
        "As we can see based on the test set instructions, given responses, and the model's responses, the model performs relatively well.\n",
        "\n",
        "But there are some wrong or suspicious answers given by the model, therefor we need an approach to calculate evaluation (performance) score of our model to understand if it's working well or bad on the held-out test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxaOWKYSaSev"
      },
      "source": [
        "Most importantly, we can see that model evaluation is not as straightforward as in the\n",
        "previous chapter, where we simply calculated the percentage of correct spam/non-spam\n",
        "class labels to obtain the classification accuracy.\n",
        "\n",
        "In practice, instruction-finetuned LLMs\n",
        "such as chatbots are evaluated via multiple approaches:\n",
        "\n",
        "1. Short-answer and multiple choice benchmarks such as MMLU (\"Measuring\n",
        "Massive Multitask Language Understanding,\" https://arxiv.org/abs/2009.\n",
        "03300), which test the general knowledge of a model.\n",
        "\n",
        "2. Human preference comparison to other LLMs, such as LMSYS chatbot\n",
        "arena (https://arena.lmsys.org).\n",
        "\n",
        "3. Automated conversational benchmarks, where another LLM like GPT-4 is\n",
        "used to evaluate the responses, such as AlpacaEval (https://tatsulab.github.io/alpaca_eval/).\n",
        "completes the request."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkqeiAnOJMl0"
      },
      "source": [
        "#### Collecting LLM responses in JSON format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDZocpwwR_KV",
        "outputId": "d0c1356e-f72e-4cf0-ba75-e713c4bda856"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/110 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'tok_emb'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[57], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, entry \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(test_data), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_data)):\n\u001b[1;32m      2\u001b[0m   input_text \u001b[38;5;241m=\u001b[39m format_input(entry)\n\u001b[0;32m----> 4\u001b[0m   token_ids \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_to_token_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcontext_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBASE_CONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43meos_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50256\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m   generated_text \u001b[38;5;241m=\u001b[39m token_ids_to_text(token_ids, tokenizer)\n\u001b[1;32m     13\u001b[0m   response_text \u001b[38;5;241m=\u001b[39m generated_text[\u001b[38;5;28mlen\u001b[39m(input_text):]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m### Response:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n",
            "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(model, idx, max_new_tokens, context_size, temperature, top_k, eos_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(model, idx, max_new_tokens, context_size, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eos_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     idx \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mto(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtok_emb\u001b[49m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_new_tokens):\n\u001b[1;32m      4\u001b[0m         idx_cond \u001b[38;5;241m=\u001b[39m idx[:, \u001b[38;5;241m-\u001b[39mcontext_size:]\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'tok_emb'"
          ]
        }
      ],
      "source": [
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "  input_text = format_input(entry)\n",
        "\n",
        "  token_ids = generate(\n",
        "      model,\n",
        "      idx=text_to_token_ids(input_text, tokenizer),\n",
        "      max_new_tokens=256,\n",
        "      context_size=BASE_CONFIG['context_length'],\n",
        "      eos_id=50256\n",
        "  )\n",
        "\n",
        "  generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "  response_text = generated_text[len(input_text):].replace('### Response:', \"\").strip()\n",
        "\n",
        "  test_data[i]['model_response'] = response_text\n",
        "\n",
        "with open('instruction-data-with-response.json', 'w') as file:\n",
        "  json.dump(test_data, file, indent=4) # \"indent\" for pretty-printing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F__XGo1HJ7cu",
        "outputId": "8a9737aa-5c4f-49ea-95dc-c563bc13d5a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': 'Rewrite the sentence using a simile.',\n",
              " 'input': 'The car is very fast.',\n",
              " 'output': 'The car is as fast as lightning.',\n",
              " 'model_response': 'The car is as fast as a bullet.'}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yQRT1yRKsEV"
      },
      "source": [
        "#### Save the model as `gpt-2-medium355M-sft.pth`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOyBKWbKKQia",
        "outputId": "a44eda7c-6ef5-4764-ecb0-4ced2d4da9fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/sf/m8d1jsv948q75r24_12s_sg00000gn/T/ipykernel_23410/693254910.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\", map_location=torch.device('mps')))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# import re\n",
        "\n",
        "# file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL)}-sft.pth\"\n",
        "# torch.save(model.state_dict(), file_name)\n",
        "# print(f\"Model saved as {file_name}\")\n",
        "\n",
        "# Load model via\n",
        "model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\", map_location=torch.device('mps')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG-RuX5MLMyt"
      },
      "source": [
        "### Evaluting the Fine-Tuned LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQZTLBtuOPbc"
      },
      "source": [
        "To implement the evaluation step which involves evaluating test set responses in an automated fashion, we utilize an existing instruction-finetuned 8b parameter LLama 3 model developed by Meta AI.\n",
        "\n",
        "This model can be run locally using the open-source Ollama aplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ollama running: True\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter(['name']):\n",
        "        if process_name in proc.info['name']:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "\n",
        "ollama_running = check_if_running('ollama')\n",
        "if not ollama_running:\n",
        "    raise RuntimeError('Ollama not running. Launch ollama before proceeding.')\n",
        "print('Ollama running:', check_if_running('ollama'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "def query_model(\n",
        "    prompt,\n",
        "    model='llama3',\n",
        "    url='http://localhost:11434/api/chat'\n",
        "):\n",
        "    # Create the data payload as a dictionary\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {  # Settings below are required for deterministic responses\n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
        "    payload = json.dumps(data).encode('utf-8')\n",
        "    \n",
        "    # Craete a request object, settting the method to POST and adding necessary headers\n",
        "    request = urllib.request.Request(\n",
        "        url,\n",
        "        data=payload,\n",
        "        method='POST'\n",
        "    )\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "    \n",
        "    # Send the request and capture the response\n",
        "    response_data = \"\"\n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        # Read and decode the response\n",
        "        while True:\n",
        "            line = response.readline().decode('utf-8')\n",
        "            if not line:\n",
        "                break\n",
        "            response_json = json.loads(line)\n",
        "            response_data += response_json['message']['content']\n",
        "    \n",
        "    return response_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Llamas are herbivores, which means they primarily feed on plant-based foods. Their diet typically consists of:\n",
            "\n",
            "1. Grasses: Llamas love to graze on various types of grasses, including tall grasses, short grasses, and even weeds.\n",
            "2. Hay: High-quality hay, such as alfalfa or timothy hay, is a staple in a llama's diet. They enjoy the sweet taste and texture of fresh hay.\n",
            "3. Grains: Llamas may receive grains like oats, barley, or corn as part of their daily ration. However, it's essential to provide these grains in moderation, as they can be high in calories.\n",
            "4. Fruits and vegetables: Llamas enjoy a variety of fruits and veggies, such as apples, carrots, sweet potatoes, and leafy greens like kale or spinach.\n",
            "5. Minerals: Llamas require access to mineral supplements, which help maintain their overall health and well-being.\n",
            "\n",
            "In the wild, llamas might also eat:\n",
            "\n",
            "1. Leaves: They'll munch on leaves from trees and shrubs, including plants like willow, alder, and birch.\n",
            "2. Bark: In some cases, llamas may eat the bark of certain trees, like aspen or cottonwood.\n",
            "3. Mosses and lichens: These non-vascular plants can be a tasty snack for llamas.\n",
            "\n",
            "In captivity, llama owners typically provide a balanced diet that includes a mix of hay, grains, and fruits/vegetables. It's essential to consult with a veterinarian or experienced llama breeder to determine the best feeding plan for your llama.\n"
          ]
        }
      ],
      "source": [
        "# Demo\n",
        "\n",
        "model = \"llama3\"\n",
        "result = query_model(\"What do Llamas eat?\", model)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': 'Rewrite the sentence using a simile.',\n",
              " 'input': 'The car is very fast.',\n",
              " 'output': 'The car is as fast as lightning.'}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'instruction': 'Rewrite the sentence using a simile.',\n",
              " 'input': 'The car is very fast.',\n",
              " 'output': 'The car is as fast as lightning.',\n",
              " 'model_response': 'The car is as fast as a bullet.'}"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Load the test data\n",
        "# with open('instruction-data-with-response.json', 'r') as file:\n",
        "#     test_data = json.load(file)\n",
        "# test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset response\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "\n",
            "Score:\n",
            ">> I'd rate the model response \"The car is as fast as a bullet.\" an 85 out of 100.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* The response uses a simile correctly, comparing the speed of the car to something else (in this case, a bullet).\n",
            "* The comparison is relevant and makes sense, as bullets are known for their high velocity.\n",
            "* The phrase \"as fast as\" is used correctly to introduce the simile.\n",
            "\n",
            "The only reason I wouldn't give it a perfect score is that some people might find the comparison slightly less vivid or evocative than using lightning (which is often associated with speed and power). However, \"as fast as a bullet\" is still a strong and effective simile that effectively conveys the idea of the car's speed.\n",
            "\n",
            "---------------------------------------\n",
            "\n",
            "Dataset response\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud typically associated with thunderstorms is a cumulus cloud.\n",
            "\n",
            "Score:\n",
            ">> I'd rate this model response as 40 out of 100.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* The model correctly identifies that it's talking about clouds related to thunderstorms.\n",
            "* However, it incorrectly states that cumulus clouds are typically associated with thunderstorms. Cumulonimbus clouds are actually the ones commonly linked with thunderstorms.\n",
            "* The response doesn't demonstrate a clear understanding of cloud types or their characteristics.\n",
            "\n",
            "To improve this score, I'd suggest retraining the model on more accurate information about different cloud types and their associations with weather phenomena.\n",
            "\n",
            "---------------------------------------\n",
            "\n",
            "Dataset response\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "\n",
            "Score:\n",
            ">> I'd score my own response as 95 out of 100. Here's why:\n",
            "\n",
            "* The response accurately answers the question by naming the author of 'Pride and Prejudice' as Jane Austen.\n",
            "* The response is clear and concise, making it easy to understand.\n",
            "* There are no grammatical errors or ambiguities that could lead to confusion.\n",
            "\n",
            "The only reason I wouldn't score it a perfect 100 is that the response is slightly redundant - it's not necessary to rephrase the question in the answer. A more concise response would be: \"Jane Austen.\"\n",
            "\n",
            "---------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for entry in test_data[:3]:\n",
        "    prompt = (\n",
        "        f\"Given the input `{format_input(entry)}` \"\n",
        "        f\"and corret output `{entry['output']}`, \"\n",
        "        f\"score the model response `{entry['model_response']}`\"\n",
        "        f\" on a scale from 0 to 100, where 100 is the best score.\"\n",
        "    )\n",
        "    \n",
        "    print('\\nDataset response')\n",
        "    print('>>', entry['output'])\n",
        "    print('\\nModel response:')\n",
        "    print('>>', entry['model_response'])\n",
        "    print('\\nScore:')\n",
        "    print('>>', query_model(prompt))\n",
        "    print('\\n---------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset response\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "\n",
            "Score:\n",
            ">> 85\n",
            "\n",
            "---------------------------------------\n",
            "\n",
            "Dataset response\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud typically associated with thunderstorms is a cumulus cloud.\n",
            "\n",
            "Score:\n",
            ">> 40\n",
            "\n",
            "---------------------------------------\n",
            "\n",
            "Dataset response\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "\n",
            "Score:\n",
            ">> 98\n",
            "\n",
            "---------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for entry in test_data[:3]:\n",
        "    prompt = (\n",
        "        f\"Given the input `{format_input(entry)}` \"\n",
        "        f\"and corret output `{entry['output']}`, \"\n",
        "        f\"score the model response `{entry['model_response']}`\"\n",
        "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "        f\"Respond with the integer number only.\"\n",
        "    )\n",
        "    \n",
        "    print('\\nDataset response')\n",
        "    print('>>', entry['output'])\n",
        "    print('\\nModel response:')\n",
        "    print('>>', entry['model_response'])\n",
        "    print('\\nScore:')\n",
        "    print('>>', query_model(prompt))\n",
        "    print('\\n---------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_model_score(json_data, json_key, model='llama3'):\n",
        "    scores = []\n",
        "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
        "        prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and corret output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry[json_key]}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "            f\"Respond with the integer number only.\"\n",
        "        )\n",
        "        score = query_model(prompt, model)\n",
        "        try:\n",
        "            scores.append(int(score))\n",
        "        except ValueError:\n",
        "            print(f\"Could not convert score: {score}\")\n",
        "            continue\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Scoring entries: 100%|| 110/110 [00:43<00:00,  2.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "51.09090909090909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "general_score_over_test_data = generate_model_score(test_data, json_key='model_response')\n",
        "\n",
        "print(np.mean(general_score_over_test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WM6-v5lBCBU0"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    'vocab_size': 50257,    # vocabulary size\n",
    "    'context_length': 256,  # Context Length\n",
    "    'emb_dim': 768,         # Embedding dimension\n",
    "    'n_heads': 12,          # Number of attention heads\n",
    "    'n_layers': 12,         # Number of layers\n",
    "    'drop_rate': 0.1,       # Dropout rate\n",
    "    'qkv_bias': False       # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('the-verdict.txt', 'r', encoding='utf-8') as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "text_data[:99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 Model From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2/torch.pi)) * \n",
    "            (x + 0.44715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4 * cfg['emb_dim']), ## Expansion\n",
    "            GELU(),                                        ## Activation\n",
    "            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim'])    ## Contraction\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, context_length, num_heads, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert(d_out % num_heads == 0), 'd_out must be divisible by num_heads'\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        \n",
    "        self.Wq = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.Wk = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.Wv = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_in) # Linear layer to combine head outputs\n",
    "        self.droput = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            'mask',\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        # (b, num_tokens, d_out)\n",
    "        queries = self.Wq(x)\n",
    "        keys = self.Wk(x)\n",
    "        values = self.Wv(x)\n",
    "        \n",
    "        # (b, num_tokens, num_heads, head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # (b, num_heads, num_tokens, head_dim)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        \n",
    "        attn_scores = queries @ keys.transpose(2, 3) # (b, num_heads, num_tokens, num_tokens)\n",
    "        \n",
    "        attn_scores = attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        \n",
    "        context_vec = attn_weights @ values\n",
    "        context_vec = context_vec.transpose(1, 2) # (b, num_tokens, num_heads, head_dim)\n",
    "        \n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out) # (b, num_tokens, d_out)\n",
    "        context_vec = self.out_proj(context_vec) # (b, num_tokens, d_in)\n",
    "        \n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg['emb_dim'],\n",
    "            d_out = cfg['emb_dim'],\n",
    "            context_length = cfg['context_length'],\n",
    "            num_heads = cfg['n_heads'],\n",
    "            dropout = cfg['drop_rate'],\n",
    "            qkv_bias = cfg['qkv_bias']\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.drop_shortcut = nn.Dropout(cfg['drop_rate'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x.shape: [B, num_tokens, emb_dim]\n",
    "        shortcut = x \n",
    "        x = self.norm1(x)           \n",
    "        x = self.att(x)            \n",
    "        x = self.drop_shortcut(x)   \n",
    "        x = x + shortcut            # Shortcut connection \n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "        \n",
    "        self.transformer_block = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg['emb_dim'], cfg['vocab_size'], bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        b, seq_len = in_idx.shape\n",
    "        tok_embed = self.tok_emb(in_idx)                                        # Token Embeddings\n",
    "        pos_embed = self.pos_emb(torch.arange(seq_len, device=in_idx.device))   # Positional Embeddings\n",
    "        x = tok_embed + pos_embed                                               # Input Embeddings\n",
    "        \n",
    "        x = self.drop_emb(x)\n",
    "        x = self.transformer_block(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size,\n",
    "        # E.g., if LLm support only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 token are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # (B, seq_len, vocab_size)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocabz_size)\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        # apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # (batch, 1)\n",
    "        \n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (batch, n_tokens+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding the LLM Model Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset Class and DataLoader Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation Loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('Train Loader:')\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print('\\nValidation Loader:')\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace('\\n', ' ')) # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, \n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set to the training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate the loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the batch\n",
    "            global_step += 1\n",
    "            \n",
    "            # Optimal evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f'Ep {epoch + 1} (Step {global_step:06d}): '\n",
    "                      f\"Train Loss {train_loss:.3f}, Val Loss {val_loss:.3f}\")\n",
    "        \n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Ep 1 (Step 000000): Train Loss 9.799, Val Loss 9.898\n",
      "Ep 1 (Step 000005): Train Loss 8.076, Val Loss 8.335\n",
      "Every effort move you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train Loss 6.631, Val Loss 7.048\n",
      "Ep 2 (Step 000015): Train Loss 6.063, Val Loss 6.607\n",
      "Every effort move you,,,,,,,,,,,,,,.                                   \n",
      "Ep 3 (Step 000020): Train Loss 5.692, Val Loss 6.491\n",
      "Ep 3 (Step 000025): Train Loss 5.628, Val Loss 6.484\n",
      "Every effort move you, and to the to the, and, and, and, and, and, and, and, and, and, and to the, and, and, and, and, and, and, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train Loss 5.483, Val Loss 7.192\n",
      "Ep 4 (Step 000035): Train Loss 4.902, Val Loss 6.343\n",
      "Every effort move you.       \"-- the a a.           \"--and a the of the a a he had the of the a, the of the a of the a, and\n",
      "Ep 5 (Step 000040): Train Loss 4.093, Val Loss 6.199\n",
      "Every effort move you know it, in a little of his pictures--I had been.  \"Oh, I was--and it's the picture to me I felt--as Jack's it.   \"I had been the picture--and it's\n",
      "Ep 6 (Step 000045): Train Loss 3.759, Val Loss 6.192\n",
      "Ep 6 (Step 000050): Train Loss 3.129, Val Loss 6.167\n",
      "Every effort move you know; and in a little Mrs.  \"--I me. \"Oh, I was his!  \"Oh, and I had been his pictures--I had the picture--the a little a little the room, I had\n",
      "Ep 7 (Step 000055): Train Loss 3.004, Val Loss 6.246\n",
      "Ep 7 (Step 000060): Train Loss 2.192, Val Loss 6.170\n",
      "Every effort move you know,\" was not that I felt as his pictures--so handsome, so that he had been no--as one of Jack's that, in the moment--as Jack himself, as once one had been _mine_--because he had been his\n",
      "Ep 8 (Step 000065): Train Loss 1.640, Val Loss 6.261\n",
      "Ep 8 (Step 000070): Train Loss 1.337, Val Loss 6.329\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train Loss 0.960, Val Loss 6.378\n",
      "Ep 9 (Step 000080): Train Loss 0.699, Val Loss 6.376\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"    \"Oh, and back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train Loss 0.456, Val Loss 6.495\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 11 (Step 000090): Train Loss 0.305, Val Loss 6.554\n",
      "Ep 11 (Step 000095): Train Loss 0.259, Val Loss 6.632\n",
      "Every effort move you?\" \"I that my hostess was \"interesting\": on that point I could have given Miss Croft the fullest reassurance. It was just because she was _not_ interesting--if I saw that, when Stroud laid in the first\n",
      "Ep 12 (Step 000100): Train Loss 0.226, Val Loss 6.675\n",
      "Ep 12 (Step 000105): Train Loss 0.134, Val Loss 6.746\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 13 (Step 000110): Train Loss 0.113, Val Loss 6.775\n",
      "Ep 13 (Step 000115): Train Loss 0.116, Val Loss 6.860\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 14 (Step 000120): Train Loss 0.085, Val Loss 6.912\n",
      "Ep 14 (Step 000125): Train Loss 0.073, Val Loss 6.911\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 15 (Step 000130): Train Loss 0.050, Val Loss 6.994\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 16 (Step 000135): Train Loss 0.051, Val Loss 7.026\n",
      "Ep 16 (Step 000140): Train Loss 0.048, Val Loss 7.094\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 17 (Step 000145): Train Loss 0.043, Val Loss 7.107\n",
      "Ep 17 (Step 000150): Train Loss 0.032, Val Loss 7.022\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 18 (Step 000155): Train Loss 0.025, Val Loss 7.057\n",
      "Ep 18 (Step 000160): Train Loss 0.025, Val Loss 7.181\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 19 (Step 000165): Train Loss 0.021, Val Loss 7.166\n",
      "Ep 19 (Step 000170): Train Loss 0.018, Val Loss 7.111\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 20 (Step 000175): Train Loss 0.027, Val Loss 7.132\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 21 (Step 000180): Train Loss 0.021, Val Loss 7.208\n",
      "Ep 21 (Step 000185): Train Loss 0.015, Val Loss 7.228\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 22 (Step 000190): Train Loss 0.010, Val Loss 7.155\n",
      "Ep 22 (Step 000195): Train Loss 0.015, Val Loss 7.178\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 23 (Step 000200): Train Loss 0.008, Val Loss 7.261\n",
      "Ep 23 (Step 000205): Train Loss 0.007, Val Loss 7.301\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 24 (Step 000210): Train Loss 0.007, Val Loss 7.272\n",
      "Ep 24 (Step 000215): Train Loss 0.007, Val Loss 7.257\n",
      "Every effort move you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 25 (Step 000220): Train Loss 0.007, Val Loss 7.289\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0004\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     22\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m---> 23\u001b[0m train_losses, val_losses, tokens_seen \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEvery effort move you\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     29\u001b[0m execution_time_minutes \u001b[38;5;241m=\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m\n",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m, in \u001b[0;36mtrain_model_simple\u001b[0;34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[0m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m calc_loss_batch(input_batch, target_batch, model, device)\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Calculate the loss gradients\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Update model weights using loss gradients\u001b[39;00m\n\u001b[1;32m     16\u001b[0m tokens_seen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m input_batch\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;66;03m# Returns the total number of elements (or tokens) in the batch\u001b[39;00m\n\u001b[1;32m     17\u001b[0m global_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/optim/adamw.py:220\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    207\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m cast(Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m], group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    209\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    210\u001b[0m         group,\n\u001b[1;32m    211\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         state_steps,\n\u001b[1;32m    218\u001b[0m     )\n\u001b[0;32m--> 220\u001b[0m     \u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/optim/adamw.py:782\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    780\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 782\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/optim/adamw.py:372\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    369\u001b[0m step_t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# Perform stepweight decay\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    375\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 50\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(model, train_loader, val_loader, \n",
    "                                                           optimizer, device, num_epochs, eval_freq=5, eval_iter=5,\n",
    "                                                           start_context='Every effort move you',\n",
    "                                                           tokenizer=tokenizer)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f'Training completed in {execution_time_minutes:.2f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    # plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the training and validation losses start to improve for the first\n",
    "epoch. However, the losses start to diverge past the second epoch. \n",
    "\n",
    "This divergence and the\n",
    "fact that the validation loss is much larger than the training loss indicate that the model is\n",
    "overfitting to the training data. \n",
    "\n",
    "We can confirm that the model memorizes the training data\n",
    "verbatim by searching for the generated text snippets, such as \"quite insensible to the\n",
    "irony\" in the \"The Verdict\" text file.\n",
    "\n",
    "\n",
    "This memorization is expected since we are working with a very, very small training\n",
    "dataset and training the model for multiple epochs. \n",
    "\n",
    "Usually, it's common to train a model\n",
    "on a much, much larger dataset for only one epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as f\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    'vocab_size': 50257,    # vocabulary size\n",
    "    'context_length': 256,  # Context Length\n",
    "    'emb_dim': 768,         # Embedding dimension\n",
    "    'n_heads': 12,          # Number of attention heads\n",
    "    'n_layers': 12,         # Number of layers\n",
    "    'drop_rate': 0.1,       # Dropout rate\n",
    "    'qkv_bias': False       # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('the-verdict.txt', 'r', encoding='utf-8') as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "text_data[:99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT2 Model From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2/torch.pi)) * \n",
    "            (x + 0.44715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg['emb_dim'], 4 * cfg['emb_dim']), ## Expansion\n",
    "            GELU(),                                        ## Activation\n",
    "            nn.Linear(4 * cfg['emb_dim'], cfg['emb_dim'])    ## Contraction\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, context_length, num_heads, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert(d_out % num_heads == 0), 'd_out must be divisible by num_heads'\n",
    "        \n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "        \n",
    "        self.Wq = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.Wk = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.Wv = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_in) # Linear layer to combine head outputs\n",
    "        self.droput = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            'mask',\n",
    "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        \n",
    "        # (b, num_tokens, d_out)\n",
    "        queries = self.Wq(x)\n",
    "        keys = self.Wk(x)\n",
    "        values = self.Wv(x)\n",
    "        \n",
    "        # (b, num_tokens, num_heads, head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # (b, num_heads, num_tokens, head_dim)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        \n",
    "        attn_scores = queries @ keys.transpose(2, 3) # (b, num_heads, num_tokens, num_tokens)\n",
    "        \n",
    "        attn_scores = attn_scores.masked_fill_(self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        \n",
    "        context_vec = attn_weights @ values\n",
    "        context_vec = context_vec.transpose(1, 2) # (b, num_tokens, num_heads, head_dim)\n",
    "        \n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out) # (b, num_tokens, d_out)\n",
    "        context_vec = self.out_proj(context_vec) # (b, num_tokens, d_in)\n",
    "        \n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in = cfg['emb_dim'],\n",
    "            d_out = cfg['emb_dim'],\n",
    "            context_length = cfg['context_length'],\n",
    "            num_heads = cfg['n_heads'],\n",
    "            dropout = cfg['drop_rate'],\n",
    "            qkv_bias = cfg['qkv_bias']\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg['emb_dim'])\n",
    "        self.norm2 = LayerNorm(cfg['emb_dim'])\n",
    "        self.drop_shortcut = nn.Dropout(cfg['drop_rate'])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x.shape: [B, num_tokens, emb_dim]\n",
    "        shortcut = x \n",
    "        x = self.norm1(x)           \n",
    "        x = self.att(x)            \n",
    "        x = self.drop_shortcut(x)   \n",
    "        x = x + shortcut            # Shortcut connection \n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg['vocab_size'], cfg['emb_dim'])\n",
    "        self.pos_emb = nn.Embedding(cfg['context_length'], cfg['emb_dim'])\n",
    "        self.drop_emb = nn.Dropout(cfg['drop_rate'])\n",
    "        \n",
    "        self.transformer_block = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg['n_layers'])]\n",
    "        )\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg['emb_dim'])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg['emb_dim'], cfg['vocab_size'], bias=False\n",
    "        )\n",
    "    \n",
    "    def forward(self, in_idx):\n",
    "        b, seq_len = in_idx.shape\n",
    "        tok_embed = self.tok_emb(in_idx)                                        # Token Embeddings\n",
    "        pos_embed = self.pos_emb(torch.arange(seq_len, device=in_idx.device))   # Positional Embeddings\n",
    "        x = tok_embed + pos_embed                                               # Input Embeddings\n",
    "        \n",
    "        x = self.drop_emb(x)\n",
    "        x = self.transformer_block(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the next token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        \n",
    "        # Crop current context if it exceeds the supported context size,\n",
    "        # E.g., if LLm support only 5 tokens, and the context size is 10\n",
    "        # then only the last 5 token are used as context\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond) # (B, seq_len, vocab_size)\n",
    "        \n",
    "        # Focus only on the last time step\n",
    "        # (batch, n_tokens, vocab_size) becomes (batch, vocabz_size)\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        # apply softmax to get probabilities\n",
    "        probas = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Get the idx of the vocab entry with the highest probability value\n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # (batch, 1)\n",
    "        \n",
    "        # Append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (batch, n_tokens+1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding the LLM Model Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, drop_last=True,\n",
    "                         num_workers=0):\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset Class and DataLoader Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation Loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "9\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print('Train Loader:')\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print('\\nValidation Loader:')\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace('\\n', ' ')) # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs, \n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "    \n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set to the training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # Calculate the loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the batch\n",
    "            global_step += 1\n",
    "            \n",
    "            # Optimal evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f'Ep {epoch + 1} (Step {global_step:06d}): '\n",
    "                      f\"Train Loss {train_loss:.3f}, Val Loss {val_loss:.3f}\")\n",
    "        \n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    \n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Ep 1 (Step 000000): Train Loss 9.798, Val Loss 9.897\n",
      "Ep 1 (Step 000005): Train Loss 8.075, Val Loss 8.335\n",
      "Every effort move you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train Loss 6.654, Val Loss 7.066\n",
      "Ep 2 (Step 000015): Train Loss 6.117, Val Loss 6.659\n",
      "Every effort move you,,,,,,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,,,,,,,,,,\n",
      "Ep 3 (Step 000020): Train Loss 5.918, Val Loss 6.574\n",
      "Ep 3 (Step 000025): Train Loss 5.793, Val Loss 6.546\n",
      "Every effort move you                                                  \n",
      "Ep 4 (Step 000030): Train Loss 5.724, Val Loss 6.508\n",
      "Ep 4 (Step 000035): Train Loss 5.666, Val Loss 6.517\n",
      "Every effort move you. \". \". \" I had the. \".   \" I had the. \" I had. \" I had the I had the-- the--. \". \". \".\n",
      "Ep 5 (Step 000040): Train Loss 5.191, Val Loss 6.476\n",
      "Every effort move you. \"I that the picture. Gisburn, I had. Gisburn, I had been the of the of the of the picture. \"I he had the of the picture, I had been the of the picture. G\n",
      "Ep 6 (Step 000045): Train Loss 4.699, Val Loss 6.335\n",
      "Ep 6 (Step 000050): Train Loss 4.149, Val Loss 6.231\n",
      "Every effort move you know a, and he had been--I had a--as his last a--as he had been--and it's had been his of the picture--as of his I had been the picture to me, and he had been a--I\n",
      "Ep 7 (Step 000055): Train Loss 4.182, Val Loss 6.221\n",
      "Ep 7 (Step 000060): Train Loss 3.256, Val Loss 6.109\n",
      "Every effort move you know to see the Riv I felt--I to the fact with a little a little: \"         \"I he had the fact my dear.     \"I looked up at the fact his\n",
      "Ep 8 (Step 000065): Train Loss 2.718, Val Loss 6.134\n",
      "Ep 8 (Step 000070): Train Loss 2.252, Val Loss 6.164\n",
      "Every effort move you?\"  \"Yes--I glanced after him, and Mrs.  \"I looked up, and the fact, and to see a smile of his pictures.  \"Oh, as his pictures, and down the room, in his\n",
      "Ep 9 (Step 000075): Train Loss 1.831, Val Loss 6.177\n",
      "Ep 9 (Step 000080): Train Loss 1.431, Val Loss 6.229\n",
      "Every effort move you?\" \"I that my hostess was \"interesting\": on the last word.    \"I looked, and that, in the moment--as Jack himself, my elbow and as his pictures with a--because he _rose his\n",
      "Ep 10 (Step 000085): Train Loss 1.033, Val Loss 6.273\n",
      "Every effort move you?\"  \"Yes--quite insensible to the fact with the last word. Gisburn's an awful simpleton, you know, and threw back his head to look up at the honour being _mine_--because he didn't want\n",
      "Training completed in 0.67 minutes\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(model, train_loader, val_loader, \n",
    "                                                           optimizer, device, num_epochs, eval_freq=5, eval_iter=5,\n",
    "                                                           start_context='Every effort move you',\n",
    "                                                           tokenizer=tokenizer)\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f'Training completed in {execution_time_minutes:.2f} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    # plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the training and validation losses start to improve for the first\n",
    "epoch. However, the losses start to diverge past the second epoch. \n",
    "\n",
    "This divergence and the\n",
    "fact that the validation loss is much larger than the training loss indicate that the model is\n",
    "overfitting to the training data. \n",
    "\n",
    "We can confirm that the model memorizes the training data\n",
    "verbatim by searching for the generated text snippets, such as \"quite insensible to the\n",
    "irony\" in the \"The Verdict\" text file.\n",
    "\n",
    "\n",
    "This memorization is expected since we are working with a very, very small training\n",
    "dataset and training the model for multiple epochs. \n",
    "\n",
    "Usually, it's common to train a model\n",
    "on a much, much larger dataset for only one epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding Strategies to Control Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_block): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (Wq): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wk): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (Wv): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (droput): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word. Gisburn's an awful simpleton\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model,\n",
    "    idx=text_to_token_ids('Every effort moves you', tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M['context_length']\n",
    ")\n",
    "\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer).replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding Strategy 1: Temperature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, inside the generate_text_simple function, we always sampled the token with the highest probability as the next token using `torch.argmax`, also known as the `greedy decoding`.\n",
    "\n",
    "To generate text with more variety, we can replace the argmax with a function that samples from a probabiltiy distribution (here, the probability scores the LLM generates for each vocabulary entry at each token generation step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    'closer': 0,\n",
    "    'every': 1,\n",
    "    'effort': 2,\n",
    "    'forward': 3,\n",
    "    'inches': 4,\n",
    "    'moves': 5, \n",
    "    'pizza': 6,\n",
    "    'toward': 7,\n",
    "    'you': 8\n",
    "}\n",
    "\n",
    "inverse_vocab = {v:k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume that we pass the input tensor through the model and the following tensor is the logit tensor given by the model\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.0907e-02, 1.6313e-03, 1.0019e-04, 5.7212e-01, 3.4190e-03, 1.3257e-04,\n",
      "        1.0120e-04, 3.5758e-01, 4.0122e-03])\n",
      "3\n",
      "forward\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "\n",
    "print(probas)\n",
    "\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "print(next_token_id)\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f'{freq} x {inverse_vocab[i]}')\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see based on the output, the word \"forward\" is sampled most of the time (582 out of 1000 times), but other tokens such as \"closer\", \"inches\", and \"toward\" will also be sampled some of the time.\n",
    "\n",
    "This means that if we replaced the argmax function with the multinomial function inside the generate_and_print_sample function, the LLM would sometimes generate text such as \"every effort moves you toward\", \"every effort moves you inches\", and \"every effort moves you closer\" instead of \"every effort moves you forward\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8530e-10, 3.5189e-26, 2.6890e-38, 9.9099e-01, 5.7569e-23, 4.4220e-37,\n",
      "        2.9718e-38, 9.0133e-03, 2.8514e-22])\n"
     ]
    }
   ],
   "source": [
    "# Apply temperature scaling\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "next_token_logits2 = next_token_logits / 0.1\n",
    "probas = torch.softmax(next_token_logits2, dim=0)\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1546, 0.0750, 0.0429, 0.2421, 0.0869, 0.0454, 0.0430, 0.2203, 0.0898])\n"
     ]
    }
   ],
   "source": [
    "next_token_logits3 = next_token_logits / 5\n",
    "probas = torch.softmax(next_token_logits3, dim=0)\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = [1, 0.1, 5]\n",
    "scaled_logits = [next_token_logits/temp for temp in temperatures]\n",
    "scaled_probas = [torch.softmax(scaled_logit, dim=0) for scaled_logit in scaled_logits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding Strategy 2: Top-k Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we saw that higher temperature values result in more uniformly distributed next-token probabilities, which result in more diverse output as it reduces the likelihood of the model repeatedly selecting the most probable token. \n",
    "\n",
    "This method alllows for exploring less likely but potentially more interesting and creative paths in the generation process.\n",
    "\n",
    "However, one downside of this approach is that it sometimes leads to grammatically incorect or completely nonsensical outputs such as \"every effort moves you pizza\".\n",
    "\n",
    "In top-k sampling, we can restrict the sampled tokens to the top-k most likely tokens and exclude all other tokens from the selection process by masking their probabiltiy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
       "         1.7900])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits:  tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions:  tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print('Top logits: ', top_logits)\n",
    "print('Top positions: ', top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits<top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Merge Temperature Scaling and Top-k Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.5100,  0.8900, -1.9000,  6.7500,  1.6300, -1.6200, -1.8900,  6.2800,\n",
       "         1.7900])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        \n",
    "        # Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "            \n",
    "        # Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            \n",
    "            # apply softmax to get probabilities\n",
    "            probas = torch.softmax(logits, dim=-1)\n",
    "            \n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probas, num_samples=1)\n",
    "            \n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        \n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        \n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you not to work on surprise. Th is to face watching me by his knees. Professional-humrecating of my way of\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "token_ids = generate(\n",
    "    model,\n",
    "    idx=text_to_token_ids('Every effort moves you', tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M['context_length'],\n",
    "    top_k= 25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print('Output text:\\n', token_ids_to_text(token_ids, tokenizer).replace('\\n', ' '))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
